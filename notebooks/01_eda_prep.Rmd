```{r}
# We load all the librarys for this notebook
library(Stat2Data)
library(dplyr)
library(purrr)

# Cargamos las funciones externas
source("../R/01_functions.R")
```

# 1. EDA and data preprocessing

We begin by loading the `Hawks` dataset from the `Stat2Data` package. TRhis dataset is a subset of a dataset orignial. Collected as part of a longitudinal study in Iowa and contains observations of three distinct species: Red-tailed, Sharp-shinned, and Cooper's Hawks. This multi-species structure makes it an ideal candidate for clustering analysis tasks.

To verify the data load, we inspect the first three observations.

```{r}
# Load data
data("Hawks")

# Display the first 3 rows of the dataset
head(Hawks, 3)
```

A preliminary inspection reveals a mix of numerical and categorical variables. We also observe missing data represented in two forms: explicit NA values (e.g., in StandardTail) and empty character strings (e.g., in ReleaseTime), which will require unification during preprocessing.

## 1.1. Variable dictionary

Si revisamos la fuente oficial del dataset (https://rdrr.io/rforge/Stat2Data/man/Hawks.html) podemos extraer informacion de cada varable:

A dataset with 908 observations on the following 19 variables.

Month	code8=September to 12=December
Day	Date in the month
Year	Year: 1992-2003
CaptureTime	Time of capture (HH:MM)
ReleaseTime	Time of release (HH:MM)
BandNumber	ID band code
Species	CH=Cooper's, RT=Red-tailed, SS=Sharp-Shinned
Age	A=Adult or I=Imature
Sex	F=Female or M=Male
Wing	Length (in mm) of primary wing feather from tip to wrist it attaches to
Weight	Body weight (in gm)
Culmen	Length (in mm) of the upper bill from the tip to where it bumps into the fleshy part of the bird
Hallux	Length (in mm) of the killing talon
Tail	Measurement (in mm) related to the length of the tail (invented at the MacBride Raptor Center)
StandardTail	Standared measurement of tail length (in mm)
Tarsus	Length of the basic foot bone (in mm)
WingPitFat	Amount of fat in the wing pit
KeelFat	Amount of fat on the breastbone (measured by feel
Crop	Amount of material in the crop, coded from 1=full to 0=empty

Per a una major comprensio del dataset, analizem els 10 primers valors valids (en cas que hi hagi) de cada variable:

```{r}
# Call the function from our sourced script
valid_unique_values <- get_unique_valid_values(Hawks, 10)

# Display results
valid_unique_values
```

En base a lo anterior podemos categorizar las variables en dos grupos principales:

Categorical Variables (Factors): Features como Species, Age, Sex, o metadatos como month or BandNumber.

Numerical Variables (Biometric Measurements): Variables continuas que representan medidas físicas como Wing, Weight, Culmen, etc.

## 1.2. Variable filtering

En esta etapa realizamos el primer gran filtro de información. 

Para empezar, variables como Month, Year, CaptureTime o BandNumber son metadatos temporales o identificadores que no aportan información sobre la morfología del ave y, por tanto, no tienen valor predictivo para distinguir especies. Las eliminaremos.

Para el siguiente paso, es fundamental entender nuestra estrategia bajo el prisma de los modelos de agrupación (K-means y DBSCAN), los cuales presentan restricciones y sensibilidades específicas. Ahora toca tratar todo el resto de cvategoricas que son realmente features de llas aves. Estas, al ser factors, no se pueden meter en nuestros modelos (ya que no aceptan factors solo numeros). Podriamos pensar en introducirlas tras hacer un encoding, pero  a diferencia de modelos basados en reglas o probabilidad (como Random Forest o Regresión Logística), donde el encoding es obligatorio y beneficioso, los modelos basados en distancia son extremadamente sensibles a la naturaleza de los datos.Si transformamos una variable como Age (Inmaduro=0, Adulto=1), estaríamos forzando una "barrera artificial" en el espacio euclídeo.
Mientras que en las variables biométricas el continuo permite separar grupos de forma natural, una variable binaria o con pocos grupos tiende a forzar la creación de grupos basados en esa dicotomía, pudiendo enmascarar las diferencias biológicas reales entre especies. Ademas, variables como edad, no tienen una influencia REAL en la reparacion entre especies, sino mas bien una separacion dentro de la propia especie. Por tanto, todas las categoricas no nos sirven. 

Por otro lado, al analizar el resumen estadístico, observamos que lasvariables  WingPitFat y KeelFat presentan un comportamiento pseudo-categórico o discreto. WingPitFat solo muestra 4 valores posibles y KeelFat apenas 8. Mantener estas variables no es objetivamente conveniente por dos razones críticas. En el clustering, estas variables crean acumulaciones de puntos en coordenadas idénticas, lo que dificulta la convergencia de los algoritmos hacia clústeres esféricos o densos. Ademas, no son tan untiles como las biometricas al momento de separa especies ya que ...

Por todo ello, decidimos mantener únicamente las variables biométricas continuas para el entrenamiento, conservando Species exclusivamente como Ground Truth para la evaluación externa posterior

```{r}
# Apply the custom function from R/functions.R
hawks_filtered <- refine_hawks_data(Hawks)

# Check the dimensions
dim(hawks_filtered)
```

## 1.3. Varaible exploration

Analicemoos ahora estas variables

```{r}
summary(hawks_filtered)
```

The summary analysis reveals three key issues that dictate our preprocessing strategy.

- Outliers: Vemos indicios de que exiten. El mejor ejemplo es Hallux. taht shows a maximum value of 341.4, which is biologically impossible given the median of 29.4. 

- NaN: Hay variables con nan. Spm espcialmente relevantes Tarsus con mas de un 90% y StandardTail con 377 de 908 obsercaciones.

- Scaling Requirements: Significant magnitude differences exist between features (e.g., Weight that arribes at ~2000g vs Culmen wix max ~39).

These issues are not merely statistical noise; they are critical roadblocks for clustering performance. The choice of algorithm—whether partition-based like K-means or density-based like DBSCAN—dictates how these flaws affect our results:

Outliers: In K-means, outliers can "pull" centroids toward extreme values, distorting the entire cluster structure or even creating artificial single-point clusters.DBSCAN is inherently more robust as it treats isolated points as "noise." However, a significant risk remains: an outlier located between two distinct high-density regions can act as a "bridge," causing the algorithm to merge two biologically separate groups into a single, incorrect cluster.

NaNs: Missing values represent a fundamental obstacle for both models. Since clustering relies on distance calculations (Euclidean, Manhattan, etc.), any observation with a NaN becomes mathematically "invisible" or impossible to locate in the multi-dimensional space.Without imputation, we would be forced to discard these rows, severely limiting our sample size and potentially losing key representatives of specific hawk species.

Scaling: The significant magnitude differences between features (e.g., Weight vs. Culmen) create a biased coordinate system. Without standardization, distance-based algorithms like K-means would be dominated by high-scale variables, effectively ignoring smaller but biologically significant measurements.In density-based models like OPTICS or DBSCAN, this lack of scaling would distort the "epsilon" ($\epsilon$) radius, stretching it along the axis of the largest variable and making it impossible to identify coherent, high-density clusters in the other dimensions.

In conclusion, son 3 cosas qued ebeo arreglar. ojo, cabe aclarar que stas cosas no necesariamente son siempre fallos: depende del mdelo. quizas pejudcican a un k means, pero cosas  como nan  o outliers, en otros modelos (como ...) pueden ser entendidos como informacion en vez de como ruido.

## 1.4. Absent values

Well center now on NaN. Hau muchas maneras de tratar los nan: imputando, interpolando... Aun asi, aquellos que tienen un gran % de nan la mejor opcion es siempre eliminarlos para no generar sesgo en un gran volumen de datoss. Asi, nosotros conservaremos solo aquellos con <30% de na y mantendremos el resto para imputarlos en el rocesamiento. No hay un % exacto, pero 30% es el gold standard: pruente pero sin ser demasaido etricto.

```{r}
# Sourced from R/functions.R
hawks_na <- drop_high_na_columns(hawks_filtered, threshold = 30)

# Verificamos qué columnas han sobrevivido
names(hawks_na)
```
Como vemos, hemos reducido el dataset a 7 variables, dos de ellas factors i otra numerica. Afortunadamente, las dos categoricas no tienen valores absentes (como vimos en el summary). Analicemos, pues, en las numericas, cuantos valores quedan:


```{r}
# Sourced from R/functions.R
audit_nas(hawks_na)
```

Debido a que es un numero pequeño de valores (max 10 NA de 908 obs), imputaciones avanzadas (como KNN) no son necesarias. Asi imputaremos con algo basico: la mediana. Porque esta? es facil y ademas, al contrario de la mitjana, no se ve afectado por otliers (como los de hallux).

```{r}
# Aplicamos la imputación
hawks_imputed <- impute_median(hawks_na)

# 3. Verificación final
audit_nas(hawks_imputed)
```


## 1.5. Outliers

le'ts handle outliers. There are many diferents maneras de descubrir un outlier. Una de las mas comunes, que usaremos aqui, es mediante el rant IQT. Mathematically, the IQR is calculated as:$$IQR = Q_3 - Q_1$$Where $Q_1$ is the 25th percentile and $Q_3$ is the 75th percentile. A data point is statistically considered an outlier if it falls outside the following boundaries:Lower Bound: $Q_1 - 1.5 \times IQR$Upper Bound: $Q_3 + 1.5 \times IQR$

In a Boxplot, these points appear as individual dots beyond the "whiskers" or tails, allowing us to quickly spot biological impossibilities like our previously noted Hallux measurement. So we'll mex boxplots for numerical variables:

```{r outlier_viz, fig.width=10, fig.height=6}
# Simply call the function from R/functions.R
plot_biometric_outliers(hawks_imputed)
```

Vemos que solo hallux tiene outliers. Aunque es posible que sean ouliers biologicamente plausibles, al ser un num bajo de ouliers (7 puntos de 908 observaciones) y tener la capacidad de distorisionar al modelo, de nuevo, lo resoveremos subtituyendolos por la mediana del atributo. Tecnicas mas avanazadas de  imputacion no son necesarias aqui debido al numero bajo. 

```{r}
# Aplicamos nuestra función de imputación
hawks_no_out <- hawks_imputed %>%
  mutate(Hallux = impute_outliers_median(Hallux))

# Verificación rápida: El máximo ya no debería ser 341
summary(hawks_no_out$Hallux)
```

## 1.7 Standarize

El siguiente paso es estandarizar las variables numericas. Estandarizaremos con Z-score. La media pasa a ser 0 y la desviación estándar 1.La fórmula matemática que aplicaremos es:$$z = \frac{x - \mu}{\sigma}$$Donde $x$ es el valor original, $\mu$ la media y $\sigma$ la desviación estándar.

```{r}
# Convertimos todas las medidas a la misma escala (Z-score)
hawks_final <- standardize_data(hawks_no_out)

# Verificamos que la media ahora sea 0 (o casi 0) y el rango sea comparable
hawks_final %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd)))
```

Llegados a este punto ya tenemos el dataset processado y limipio para el modelaje:

```{r}
head(hawks_final, 3)
```


## 1.1 Visual representation

Vamos a intentar entenderlo mejor, mediante represetnaciones visuales

### 1.7.1 Freq graund truth

### 1.7.2 Distribución de Numéricas

### 1.7.3 Matriz de Correlación

### 1.7.4 Pairplot
