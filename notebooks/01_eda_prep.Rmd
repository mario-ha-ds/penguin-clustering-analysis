```{r}
# We load all the librarys for this notebook
library(Stat2Data)
library(dplyr)
library(purrr)
library(ggplot2)
library(corrplot)
library(GGally)

# Cargamos las funciones externas
source("../R/01_functions.R")
```

# 1. EDA and data preprocessing

We begin by loading the `Hawks` dataset from the `Stat2Data` package. TRhis dataset is a subset of a dataset orignial. Collected as part of a longitudinal study in Iowa and contains observations of three distinct species: Red-tailed, Sharp-shinned, and Cooper's Hawks. This multi-species structure makes it an ideal candidate for clustering analysis tasks.

To verify the data load, we inspect the first three observations.

```{r}
# Cargamos el dataset desde la carpeta local /data. 
# Nota: Aunque los datos están disponibles en la librería 'Stat2Data', 
# usamos el archivo local (descargado en la fecha de creacion del proyecto) para garantizar la reproducibilidad y evitar 
# inconsistencias ante futuras actualizaciones de la librería.
Hawks <- read.csv("../data/Hawks.csv")

# Visualizamos las primeras 3 filas para confirmar la carga correcta
head(Hawks, 3)
```

A preliminary inspection reveals a mix of numerical and categorical variables. We also observe missing data represented in two forms: explicit NA values (e.g., in StandardTail) and empty character strings (e.g., in ReleaseTime), which will require unification during preprocessing.

## 1.1. Variable dictionary

Si revisamos la fuente oficial del dataset (https://rdrr.io/rforge/Stat2Data/man/Hawks.html) podemos extraer informacion de cada varable:

A dataset with 908 observations on the following 19 variables.

Month	code8=September to 12=December
Day	Date in the month
Year	Year: 1992-2003
CaptureTime	Time of capture (HH:MM)
ReleaseTime	Time of release (HH:MM)
BandNumber	ID band code
Species	CH=Cooper's, RT=Red-tailed, SS=Sharp-Shinned
Age	A=Adult or I=Imature
Sex	F=Female or M=Male
Wing	Length (in mm) of primary wing feather from tip to wrist it attaches to
Weight	Body weight (in gm)
Culmen	Length (in mm) of the upper bill from the tip to where it bumps into the fleshy part of the bird
Hallux	Length (in mm) of the killing talon
Tail	Measurement (in mm) related to the length of the tail (invented at the MacBride Raptor Center)
StandardTail	Standared measurement of tail length (in mm)
Tarsus	Length of the basic foot bone (in mm)
WingPitFat	Amount of fat in the wing pit
KeelFat	Amount of fat on the breastbone (measured by feel
Crop	Amount of material in the crop, coded from 1=full to 0=empty

Per a una major comprensio del dataset, analizem els 10 primers valors valids (en cas que hi hagi) de cada variable:

```{r}
# Call the function from our sourced script
valid_unique_values <- get_unique_valid_values(Hawks, 10)

# Display results
valid_unique_values
```

En base a lo anterior podemos categorizar las variables en dos grupos principales:

Categorical Variables (Factors): Features como Species, Age, Sex, o metadatos como month or BandNumber.

Numerical Variables (Biometric Measurements): Variables continuas que representan medidas físicas como Wing, Weight, Culmen, etc.

## 1.2. Variable filtering

En esta etapa realizamos el primer gran filtro de información. 

Para empezar, variables como Month, Year, CaptureTime o BandNumber son metadatos temporales o identificadores que no aportan información sobre la morfología del ave y, por tanto, no tienen valor predictivo para distinguir especies. Las eliminaremos.

Para el siguiente paso, es fundamental entender nuestra estrategia bajo el prisma de los modelos de agrupación (K-means y DBSCAN), los cuales presentan restricciones y sensibilidades específicas. Ahora toca tratar todo el resto de cvategoricas que son realmente features de llas aves. Estas, al ser factors, no se pueden meter en nuestros modelos (ya que no aceptan factors solo numeros). Podriamos pensar en introducirlas tras hacer un encoding, pero  a diferencia de modelos basados en reglas o probabilidad (como Random Forest o Regresión Logística), donde el encoding es obligatorio y beneficioso, los modelos basados en distancia son extremadamente sensibles a la naturaleza de los datos.Si transformamos una variable como Age (Inmaduro=0, Adulto=1), estaríamos forzando una "barrera artificial" en el espacio euclídeo.
Mientras que en las variables biométricas el continuo permite separar grupos de forma natural, una variable binaria o con pocos grupos tiende a forzar la creación de grupos basados en esa dicotomía, pudiendo enmascarar las diferencias biológicas reales entre especies. Ademas, variables como edad, no tienen una influencia REAL en la reparacion entre especies, sino mas bien una separacion dentro de la propia especie. Por tanto, todas las categoricas no nos sirven. 

Por otro lado, al analizar el resumen estadístico, observamos que lasvariables  WingPitFat y KeelFat presentan un comportamiento pseudo-categórico o discreto. WingPitFat solo muestra 4 valores posibles y KeelFat apenas 8. Mantener estas variables no es objetivamente conveniente por dos razones críticas. En el clustering, estas variables crean acumulaciones de puntos en coordenadas idénticas, lo que dificulta la convergencia de los algoritmos hacia clústeres esféricos o densos. Ademas, no son tan untiles como las biometricas al momento de separa especies ya que ...

Por todo ello, decidimos mantener únicamente las variables biométricas continuas para el entrenamiento, conservando Species exclusivamente como Ground Truth para la evaluación externa posterior

```{r}
# Apply the custom function from R/functions.R
hawks_filtered <- refine_hawks_data(Hawks)

# Check the dimensions
dim(hawks_filtered)
```

## 1.3. Varaible exploration

Analicemoos ahora estas variables

```{r}
summary(hawks_filtered)
```

The summary analysis reveals three key issues that dictate our preprocessing strategy.

- Outliers: Vemos indicios de que exiten. El mejor ejemplo es Hallux. taht shows a maximum value of 341.4, which is biologically impossible given the median of 29.4. It is probbably a human transcription error (there not exis this birds with 34cm of hallux).

- NaN: Hay variables con nan. Spm espcialmente relevantes Tarsus con mas de un 90% y StandardTail con 377 de 908 obsercaciones.

- Scaling Requirements: Significant magnitude differences exist between features (e.g., Weight that arribes at ~2000g vs Culmen wix max ~39).

These issues are not merely statistical noise; they are critical roadblocks for clustering performance. The choice of algorithm—whether partition-based like K-means or density-based like DBSCAN—dictates how these flaws affect our results:

Outliers: In K-means, outliers can "pull" centroids toward extreme values, distorting the entire cluster structure or even creating artificial single-point clusters.DBSCAN is inherently more robust as it treats isolated points as "noise." However, a significant risk remains: an outlier located between two distinct high-density regions can act as a "bridge," causing the algorithm to merge two biologically separate groups into a single, incorrect cluster.

NaNs: Missing values represent a fundamental obstacle for both models. Since clustering relies on distance calculations (Euclidean, Manhattan, etc.), any observation with a NaN becomes mathematically "invisible" or impossible to locate in the multi-dimensional space.Without imputation, we would be forced to discard these rows, severely limiting our sample size and potentially losing key representatives of specific hawk species.

Scaling: The significant magnitude differences between features (e.g., Weight vs. Culmen) create a biased coordinate system. Without standardization, distance-based algorithms like K-means would be dominated by high-scale variables, effectively ignoring smaller but biologically significant measurements.In density-based models like OPTICS or DBSCAN, this lack of scaling would distort the "epsilon" ($\epsilon$) radius, stretching it along the axis of the largest variable and making it impossible to identify coherent, high-density clusters in the other dimensions.

In conclusion, son 3 cosas qued ebeo arreglar. ojo, cabe aclarar que stas cosas no necesariamente son siempre fallos: depende del mdelo. quizas pejudcican a un k means, pero cosas  como nan  o outliers, en otros modelos (como ...) pueden ser entendidos como informacion en vez de como ruido.

## 1.4. Absent values

Well center now on NaN. Hau muchas maneras de tratar los nan: imputando, interpolando... Aun asi, aquellos que tienen un gran % de nan la mejor opcion es siempre eliminarlos para no generar sesgo en un gran volumen de datoss. Asi, nosotros conservaremos solo aquellos con <30% de na y mantendremos el resto para imputarlos en el rocesamiento. No hay un % exacto, pero 30% es el gold standard: pruente pero sin ser demasaido etricto.

```{r}
# Sourced from R/functions.R
hawks_na <- drop_high_na_columns(hawks_filtered, threshold = 30)

# Verificamos qué columnas han sobrevivido
names(hawks_na)
```
Como vemos, hemos reducido el dataset a 7 variables, dos de ellas factors i otra numerica. Afortunadamente, las dos categoricas no tienen valores absentes (como vimos en el summary). Analicemos, pues, en las numericas, cuantos valores quedan:


```{r}
# Sourced from R/functions.R
audit_nas(hawks_na)
``` 

Debido a que es un numero pequeño de valores (max 10 NA de 908 obs), imputaciones avanzadas (como KNN) no son necesarias. Asi imputaremos con algo basico: la mediana. Porque esta? es facil y ademas, al contrario de la mitjana, no se ve afectado por otliers (como los de hallux).

```{r}
# Aplicamos la imputación
hawks_imputed <- impute_median(hawks_na)

# 3. Verificación final
audit_nas(hawks_imputed)
```


## 1.5. Outliers

le'ts handle outliers. There are many diferents maneras de descubrir un outlier. Una de las mas comunes, que usaremos aqui, es mediante el rant IQT. Mathematically, the IQR is calculated as:$$IQR = Q_3 - Q_1$$Where $Q_1$ is the 25th percentile and $Q_3$ is the 75th percentile. A data point is statistically considered an outlier if it falls outside the following boundaries:Lower Bound: $Q_1 - 1.5 \times IQR$Upper Bound: $Q_3 + 1.5 \times IQR$

In a Boxplot, these points appear as individual dots beyond the "whiskers" or tails, allowing us to quickly spot biological impossibilities like our previously noted Hallux measurement. So we'll mex boxplots for numerical variables:

```{r outlier_viz, fig.width=10, fig.height=6}
# Simply call the function from R/functions.R
plot_biometric_outliers(hawks_imputed)
```

Vemos que solo hallux tiene outliers. Aunque es posible que sean ouliers biologicamente plausibles, al ser un num bajo de ouliers (7 puntos de 908 observaciones) y tener la capacidad de distorisionar al modelo, de nuevo, lo resoveremos subtituyendolos por la mediana del atributo. Tecnicas mas avanazadas de  imputacion no son necesarias aqui debido al numero bajo. 

```{r}
# Aplicamos nuestra función de imputación
hawks_no_out <- hawks_imputed %>%
  mutate(Hallux = impute_outliers_median(Hallux))

# Verificación rápida: El máximo ya no debería ser 341
summary(hawks_no_out$Hallux)
```

## 1.7 Standarize

El siguiente paso es estandarizar las variables numericas. Estandarizaremos con Z-score. La media pasa a ser 0 y la desviación estándar 1.La fórmula matemática que aplicaremos es:$$z = \frac{x - \mu}{\sigma}$$Donde $x$ es el valor original, $\mu$ la media y $\sigma$ la desviación estándar.

```{r}
# Convertimos todas las medidas a la misma escala (Z-score)
hawks_norm <- standardize_data(hawks_no_out)

# Verificamos que la media ahora sea 0 (o casi 0) y el rango sea comparable
hawks_norm %>%
  summarise(across(where(is.numeric), list(mean = mean, sd = sd)))
```

Llegados a este punto ya tenemos el dataset processado y limipio para el modelaje:

```{r}
head(hawks_norm, 3)
```


## 1.7 Visual representation

Vamos a intentar entender el dataset mejor, mediante represetnaciones visuales

### 1.7.1 Freq graund truth

El primer paso es ver como esta distribuido nuestro graund truth.  

```{r fig.width=7, fig.height=4, fig.align='center'}
# Simply call the function from our sourced script
plot_species_frequency(hawks_norm)
```
Vemis que las tritribuciones no son equivalentes, mientras la especie RT tiene 577 individuis, CH teiene un insignificante 70, mientra que ss 261. Esto implica que ... (como afectara al k means y a dbscan)

### 1.7.2 Distribución de numéricas

Pasemos a analizar como se distribuyen las variables numericas segun el grupo de verdad biologica mediante graficos de distribucion.

```{r numeric_dist, fig.width=10, fig.height=7, fig.align='center'}
# Generamos el panel de densidades y lo guardamos en output
plot_numeric_distributions(hawks_norm, save_plot = TRUE)
```
En general, observamos una excelente separación entre grupos. Las "montañas" (densidades) muestran que los picos de cada especie no coinciden, lo que facilita la distinción morfológica.

Culmen y Hallux parecen ser las mejores discriminadoras, seguidas de cerca por Weight y Wing. La variable Tail presenta el mayor solapamiento, especialmente entre CH y RT.

Igualmente, la clara diferenciación de las distribuciones es una noticia excelente; sugiere que los algoritmos de clustering podrán identificar las especies con éxito basándose en estos perfiles biométricos diferenciados.


### 1.7.3 Matriz de Correlación

Pasemos ahora a hacer un grafico de correlacion. Esto nos permitira analizar que tan relacionadas estan las variables y descrubir posibles redundancias

```{r fig.width=8, fig.height=8, fig.align='center'}
# Generamos y guardamos usando el código optimizado
plot_correlation_matrix(hawks_norm, save_plot = TRUE)
```
El dataset presenta una correlación extremadamente alta en todas sus dimensiones. Los valores oscilan entre un 0.87 (mínimo, entre Weight y Tail) y un 0.95 (máximo, entre Culmen y Wing o Weight).

En Data Science, valores superiores a 0.90 indican una redundancia casi total. Es decir, en este conjunto de datos las variables se comportan de forma síncrona (por ej, si el peso aumenta, el ala o la cola crecen proporcionalmente).

Modelos como k means son sensibles a estas redundancias ... (explica como)

Asi, debemos tratarlas. Aplicar un filtro de eliminación simple (umbral > 0.85) nos dejaría prácticamente con una sola variable. Por ello, en lugar de eliminar datos arbitrariamente, optaremos por la Reducción de Dimensionalidad mediante PCA en la siguiente fase.

### 1.7.4 Pairplot

Como análisis final del EDA, integramos todas las métricas en un único visual para confirmar la estructura del espacio multivariante: un pairplot.

```{r pairplot, fig.width=12, fig.height=10, fig.align='center', message=FALSE}
# Generamos el mapa completo de relaciones y lo guardamos
plot_pairplot(hawks_norm, save_plot = TRUE)
```
Este gráfico combina las densidades (diagonal), las correlaciones (superior) y los scatter plots (inferior), permitiendo extraer conclusiones críticas:

Separación Física: Los gráficos de dispersión muestran nubes de puntos claramente desplazadas. Los Red-tailed (rojo) dominan el extremo superior derecho, confirmando que es la especie de mayor tamaño. Por el contrario, los Sharp-shinned (verde) se agrupan en el extremo inferior izquierdo, siendo la especie más pequeña. Los Cooper's (azul) se sitúan en una zona intermedia, solapándose ligeramente con los individuos más grandes de la especie verde.

Morfología: La forma elíptica y estirada de las nubes confirma la alta linealidad del crecimiento de los halcones.

Variabilidad por especie: Los coeficientes a la derecha revelan matices biológicos: en Wing vs Tail, la correlación es muy rígida para los verdes (0.87), pero mucho más dispersa para los azules (0.32), indicando que los Red-tailed poseen una variabilidad morfológica individual mucho mayor.

En definitiva, la combinación de alta correlación y grupos físicamente separados justifica plenamente el uso de PCA para obtener el dataset final que alimentará nuestros modelos de clustering.

## 1.8. Principal Component Analysis

El PCA nos permite transformar estas variables correlacionadas en un nuevo conjunto de variables incorrelacionadas denominadas Componentes Principales (PCs).

Los pasos son
1. Estandarización paramedia 0 y varianza 1. esto ya lo hicimos previamente

Matriz de Covarianza: Se calcula la matriz $C$ para entender cómo varían las variables entre sí.

Descomposición en Autovalores y Autovectores: Resolvemos la ecuación característica:

$$C\vec{v} = \lambda\vec{v}$$
Los Autovectores ($\vec{v}$) definen la dirección de los nuevos ejes (los Componentes Principales).Los Autovalores ($\lambda$) indican la cantidad de varianza (información) que retiene cada componente.

Proyección: Los datos originales se proyectan sobre estos nuevos ejes. El PC1 será la dirección con mayor dispersión de los datos, el PC2 la segunda, y así sucesivamente, siendo todos ortogonales (perpendiculares) entre sí.


```{r}
# Seleccionamos solo las columnas numéricas de nuestro dataset normalizado
hawks_numeric <- hawks_norm %>% select(where(is.numeric))

# Ejecutamos nuestra función manual
pca_manual <- calculate_pca(hawks_numeric)

# Mostramos los autovectores (Loadings)
# Esto nos dice cuánto pesa cada variable original en cada PC
print(pca_manual$vectors)
```
Esta tabla de loadings revela la estructura subyacente de tu dataset: el PC1 actúa como un índice de "size factor", ya que todas las variables (qque sonrelativas a tamaño) aportan de forma equitativa y con el mismo signo (negativo), confirmando la altísima correlación del EDA. El PC2 representa un factor de "forma o proporción", donde destaca la oposición entre el peso y la longitud de la cola (signos opuestos), permitiendo diferenciar aves robustas de aves estilizadas.El PC3 se especializa casi exclusivamente en la varianza del Hallux, dejando para los PC4 y PC5 los residuos técnicos y el ruido menor de variables como el ala y el culmen.

Ahora bien, no nos vamos a quedar con todas podriamos (debido a que son pocas), lo ideal es siempre reducirlas ya que las ultimas suelen aportr solo ruido. lo normal es seleccionar las que expliquen la mayor parte de la varianc, usando por ejemlo el 90 % de ella cmo limite. Para escogerlas, las representaremos graficamente en un scree plot donde su altura represetne al varianza.

```{r fig.width=8, fig.height=5, fig.align='center'}
# Usamos los resultados del cálculo manual anterior
plot_pca_variance(pca_manual)
```
Vemos que sorprendentemente la primera variable supera el 90% de varianza explicada. seguramente debido a ...
Podriamos quedarnos y entrenar con ella, aunque modeloizas con solo una variable no es lo ideal. Asi, para ser conservadores, seleccionaremos tanto la pca1 como la pca2 (esta ultima podria darnos pequeños detalles sutiles) para el entreno, asegurando la vairanza explicada suficiente, sin multicolinealidad.

Asi, como dataset final, generaremos un ultimo dataset que contenga la varaiable species (que usaremos para la avalaucion externa) i las dos pca. 

```{r}
# Llamamos a la función para crear el objeto en memoria
hawks_pca_final <- create_pca_df(pca_manual, hawks_final$Species)

# Verificamos que se haya creado bien
head(hawks_pca_final, 3)
```


